{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "import mlflow\n",
    "\n",
    "from aidefender.exp.datasets import BaseImagesDataset\n",
    "from aidefender.exp.models import BaseModel\n",
    "from aidefender.utils.mlflow import load_model, create_art_model\n",
    "from aidefender.robustness import robustness_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-jurisdiction",
   "metadata": {},
   "source": [
    "# Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../artifacts/data/RP2K_small/'\n",
    "model_path = os.path.join(tempfile.mkdtemp(), 'model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-sudan",
   "metadata": {},
   "source": [
    "# Declare dataset class\n",
    "\n",
    "If you want to train a model on a new data, all you need to do is just to create a new dataset class which would define the labels, deriving it from `aidefender.exp.datasets.BaseImagesDataset`, as shown below. \n",
    "\n",
    "The data should be placed into subdirectories corresponding to the labels. For example:\n",
    "```\n",
    "data/\n",
    "    milk/image1.jpg\n",
    "    milk/image2.jpg\n",
    "    coffee/image1.jpg\n",
    "    coffee/image2.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RP2KDataset(BaseImagesDataset):\n",
    "    LABELS = [\n",
    "        'coffee', 'juice', 'milk', 'soda', 'tea', 'vinegar', 'alcohol',\n",
    "        'beanpaste', 'cigarettes', 'seasoning', 'yoghurt',\n",
    "    ]\n",
    "\n",
    "    def _load_images_labels(self, data_path):\n",
    "        images, labels = load_image_dataset(data_path, RP2KDataset.LABELS, file_format='jpg')\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RP2KDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-carnival",
   "metadata": {},
   "source": [
    "# Declare the model\n",
    "\n",
    "Similarly, if you want to define a new model, all you need to do is subclass the `aidefender.exp.models.BaseModel` class, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSmallModel(BaseModel):\n",
    "    def __init__(self, nb_classes, normalize_mean, normalize_std):\n",
    "        super().__init__(normalize_mean, normalize_std)\n",
    "\n",
    "        self.nb_classes = nb_classes\n",
    "\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(32 * 5 * 5, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, self.nb_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, images):\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        # does normalization and transposes the images to PyTorch format\n",
    "        images = super().forward(images)\n",
    "\n",
    "        features = self.conv(images)\n",
    "        features = features.contiguous().view(batch_size, -1)\n",
    "\n",
    "        logits = self.fc(features)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvSmallModel(dataset.nb_classes, dataset.images_mean, dataset.images_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-nickel",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, nb_epochs=5):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': Accuracy(),\n",
    "        'nll': Loss(criterion)\n",
    "    }\n",
    "    evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        dataset.train = False\n",
    "\n",
    "        evaluator.run(dataloader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        print(f\"Epoch[{trainer.state.epoch}] Train: Accuracy: {metrics['accuracy']:.2f} | Loss: {metrics['nll']:.2f}\")\n",
    "\n",
    "        dataset.train = True\n",
    "\n",
    "    dataset.train = True\n",
    "    trainer.run(dataloader, max_epochs=nb_epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, dataset, nb_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-basement",
   "metadata": {},
   "source": [
    "# Save the model in MLflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "mlflow.pytorch.save_model(model, model_path, signature=dataset.model_signature)\n",
    "print(f'Model saved: {model} -> {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-clone",
   "metadata": {},
   "source": [
    "# Evaluate the model with aidefender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-repository",
   "metadata": {},
   "source": [
    "## Load the model and convert it into ART format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_model = create_art_model(mlflow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(art_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-retirement",
   "metadata": {},
   "source": [
    "## Calc robustness accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = robustness_accuracy(art_model, dataset.images, attack_name='fgsm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Robustenss accuracy: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-picture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
